{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainer Notebook\n",
    "\n",
    "This notebook is structured into 4 sections:\n",
    "* Motivation\n",
    "* Basic Stats\n",
    "* Tools, theory and analysis\n",
    "* Discussion\n",
    "\n",
    "The starting point will be numerous imports relevant for the entire notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import netwulf as nw\n",
    "import community as community_louvain\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "This brief section will cover the motivation behind this project.\n",
    "\n",
    "* What is your dataset?\n",
    "\n",
    "The dataset behind this project is the Pokémon world, i.e. all the Pokémon found in the Pokédex using PokeAPI, and all the episodes from the Pokémon TV-show collected from Bulbapedia. Using the Pokédex, it was possible to extract all the names of each Pokémon as well as some attributes such as their type, abilities, and egg groups which are important in the games. From Bulbapedia, it was possible to scrape the plots of each episode from each season as well as lists of which Pokémon appeared in which episodes. This is relevant for graph purposes. \n",
    "\n",
    "* Why did you choose this/these particular dataset(s)?\n",
    "\n",
    "We initially thought it would be interesting to go in a different direction than taking a \"real-world\" dataset, and see if it was still possible to apply methods from this course, and perform a relevant analysis. As such, we needed as much data from the Pokémon world as possible such that it was both possible to construct a graph with a number of attributes, and also have some text to analyse. \n",
    "\n",
    "* What was your goal for the end user’s experience?\n",
    "\n",
    "The goal for the end user is to gain insight into the Pokémon world, and get a brief grasp of the different seasons, what separates them, and what makes them unique. This is the hope for someone who would come across this project. Essentially, this project can be boiled down to the following research questions:\n",
    "1. Bla\n",
    "2. Bla\n",
    "3. Bla\n",
    "\n",
    "These will lead the analysis done below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Stats\n",
    "\n",
    "Now, the focus will be shifted onto data collection and preprocessing. For this, numerous functions will be used, and these will be defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scrape():\n",
    "    # scrape the data from PokéAPI\n",
    "    temp_dict = {\n",
    "        'pokemon': [],\n",
    "        'abilities': [], \n",
    "        'types': [], \n",
    "        'egg_groups': [], \n",
    "        'moves': [],\n",
    "        'pokedex_entry': []\n",
    "    }\n",
    "    \n",
    "    for i, name in tqdm(enumerate(pokemons)):\n",
    "        r = requests.get('https://pokeapi.co/api/v2/pokemon/' + str(i+1)).json()\n",
    "        # append the name of the pokemon\n",
    "        temp_dict['pokemon'].append(name)\n",
    "\n",
    "        # append the abilities of the pokemon\n",
    "        abilities = [r['abilities'][j]['ability']['name'] for j in range(len(r['abilities']))]\n",
    "        temp_dict['abilities'].append(abilities)\n",
    "\n",
    "        # append the types of the pokemon\n",
    "        types = [r['types'][i]['type']['name'] for i in range(len(r['types']))]\n",
    "        temp_dict['types'].append(types)\n",
    "\n",
    "        # append the moves of the pokemon\n",
    "        moves = [r['moves'][j]['move']['name'] for j in range(len(r['moves']))]\n",
    "        temp_dict['moves'].append(moves)\n",
    "\n",
    "        # make new request to get the egg groups and pokedex entry\n",
    "        r = requests.get('https://pokeapi.co/api/v2/pokemon-species/' + str(i+1)).json()\n",
    "\n",
    "        # append the egg groups of the pokemon\n",
    "        egg_groups = [r['egg_groups'][j]['name'] for j in range(len(r['egg_groups']))]\n",
    "        temp_dict['egg_groups'].append(egg_groups)\n",
    "\n",
    "        # append the pokedex entry of the pokemon\n",
    "        entry = r['flavor_text_entries'][0]['flavor_text'].replace('\\n', ' ').replace('\\f', ' ') if len(r['flavor_text_entries']) > 0 else None\n",
    "        temp_dict['pokedex_entry'].append(entry)\n",
    "        \n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "    return temp_dict\n",
    "\n",
    "def find_unique(df, col):\n",
    "    vals = df[col].values\n",
    "    all_vals = [item for sublist in vals for item in sublist]\n",
    "    unique_vals = list(set(all_vals))\n",
    "    return unique_vals\n",
    "\n",
    "def get_text_entries(attribute, unique_vals):\n",
    "    temp_dict = {\n",
    "        attribute: [],\n",
    "        'text_entry': []\n",
    "    }\n",
    "\n",
    "    for i, val in tqdm(enumerate(unique_vals)):\n",
    "        r = requests.get('https://pokeapi.co/api/v2/' + attribute + '/' + val).json()\n",
    "        \n",
    "        # check if the text entry exists in english\n",
    "        if len(r['effect_entries']) == 0:\n",
    "            for j in range(len(r['flavor_text_entries'])):\n",
    "                if r['flavor_text_entries'][j]['language']['name'] == 'en':\n",
    "                    temp_dict[attribute].append(val)\n",
    "                    temp_dict['text_entry'].append(r['flavor_text_entries'][j]['flavor_text'].replace('\\n', ' ').replace('\\f', ' '))\n",
    "                    break\n",
    "        else:\n",
    "            for j in range(len(r['effect_entries'])):\n",
    "                if r['effect_entries'][j]['language']['name'] == 'en':\n",
    "                    temp_dict[attribute].append(val)\n",
    "                    temp_dict['text_entry'].append(r['effect_entries'][j]['effect'].replace('\\n', ' ').replace('\\f', ' '))\n",
    "                    break\n",
    "\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the first 5 pokemons:  ['bulbasaur', 'ivysaur', 'venusaur', 'charmander', 'charmeleon']\n"
     ]
    }
   ],
   "source": [
    "# make the initial request to get the pokemon names\n",
    "data = requests.get('https://pokeapi.co/api/v2/pokemon?limit=1000').json()['results']\n",
    "\n",
    "# get the names of the pokemons\n",
    "pokemons = []\n",
    "# get the name of the pokemon\n",
    "for i in range(len(data)):\n",
    "    pokemons.append(data[i]['name'])\n",
    "\n",
    "print(\"Check the first 5 pokemons: \", pokemons[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "# next, use the function to create the dataset (only if the file does not exist)\n",
    "if not os.path.exists('pokemon.pickle'):     \n",
    "    print('Scraping data...')\n",
    "    poke_dict = data_scrape()\n",
    "    poke_df = pd.DataFrame(poke_dict)\n",
    "    poke_df.to_pickle('pokemon.pickle')\n",
    "else:\n",
    "    poke_df = pd.read_pickle('pokemon.pickle')\n",
    "    print('Data loaded!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   pokemon        1000 non-null   object\n",
      " 1   abilities      1000 non-null   object\n",
      " 2   types          1000 non-null   object\n",
      " 3   egg_groups     1000 non-null   object\n",
      " 4   moves          1000 non-null   object\n",
      " 5   pokedex_entry  905 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the info of the dataframe to get a quick overview\n",
    "poke_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the initial dataframe has been gathered there is a need for some cleaning. This is done in 2 simple steps:\n",
    "1. Remove all NaN values. These are the entries that does not have a pokedex entry.\n",
    "2. Capitalize the names of each Pokémon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, remove NaN values\n",
    "poke_df_clean = poke_df.dropna()\n",
    "\n",
    "# second, capitalize the pokemon names\n",
    "poke_df_clean['pokemon'] = poke_df_clean['pokemon'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "# finally, we save the cleaned dataframe to a pickle file (only if the file does not exist)\n",
    "poke_df_clean.to_pickle('pokemon_clean.pickle') if not os.path.exists('pokemon_clean.pickle') else print('File already exists')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to check the unique values in each of the columns of the dataframe. This is simply to gain a quick overview of how many there are of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pokemon:  905\n",
      "Number of unique abilities:  249\n",
      "Number of unique types:  18\n",
      "Number of unique egg groups:  15\n",
      "Number of unique moves:  747\n"
     ]
    }
   ],
   "source": [
    "unique_abilities = find_unique(poke_df_clean, 'abilities')\n",
    "unique_types = find_unique(poke_df_clean, 'types')\n",
    "unique_egg_groups = find_unique(poke_df_clean, 'egg_groups')\n",
    "unique_moves = find_unique(poke_df_clean, 'moves')\n",
    "print('Number of pokemon: ', len(poke_df_clean))\n",
    "print('Number of unique abilities: ', len(unique_abilities))\n",
    "print('Number of unique types: ', len(unique_types))\n",
    "print('Number of unique egg groups: ', len(unique_egg_groups))\n",
    "print('Number of unique moves: ', len(unique_moves))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sums up the initial dataset preprocessing. This means that going forward, this project will only consider the 905 Pokémon found above. It is important to note that there are 249 unique abilities, 18 unique types and 15 unique egg groups, and this will become important during the graph analysis. Do however also note, there are many more combinations of these.\n",
    "\n",
    "The next step is to collect data from all the Pokémon seasons. This process is a little more complicated, and as before it starts with defining a couple of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_number(num):\n",
    "    if num < 10:\n",
    "        return '00' + str(num)\n",
    "    elif num < 100:\n",
    "        return '0' + str(num)\n",
    "    else:\n",
    "        return str(num)\n",
    "        \n",
    "def get_pokemon_data(episode, names, season):\n",
    "    lookup = season_dict[season]\n",
    "    r = requests.get(os.path.join('https://bulbapedia.bulbagarden.net/wiki', lookup + episode)).text\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    elems = soup.find_all('a', href=True)\n",
    "    episode_pokemon = []\n",
    "\n",
    "    for name in names:\n",
    "        for elem in elems:\n",
    "            if name in elem.text:\n",
    "                text = elem.text\n",
    "                episode_pokemon.append(text)\n",
    "\n",
    "    unique_pokemon = list(set(episode_pokemon))\n",
    "\n",
    "    # remove elements that are not single words\n",
    "    unique_pokemon = [p for p in unique_pokemon if len(p.split()) == 1]\n",
    "\n",
    "    # remove nature names\n",
    "    if 'Nature' in unique_pokemon:\n",
    "        unique_pokemon.remove('Nature')\n",
    "    return unique_pokemon\n",
    "\n",
    "# get episode plots\n",
    "def get_episode_plot(episode, season):\n",
    "    lookup = season_dict[season]\n",
    "    r = requests.get(os.path.join('https://bulbapedia.bulbagarden.net/wiki', lookup + episode)).text\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    elems = soup.find_all('p')\n",
    "    plot = ''\n",
    "    for i in range(1,len(elems)):\n",
    "        if \"Who's That Pokémon?\" in elems[i].text:\n",
    "            break\n",
    "        plot += elems[i].text\n",
    "\n",
    "    #plot = plot.replace('\\n ', ' ')\n",
    "    plot = plot.replace('\\n', ' ')\n",
    "\n",
    "    # remove trailing whitespace\n",
    "    plot = plot.strip()\n",
    "    \n",
    "    return plot\n",
    "\n",
    "def gather_pokemon_data(episode_numbers, names, season):\n",
    "    episode_dict = {}\n",
    "    for episode in tqdm(episode_numbers):\n",
    "        episode_pokemon = get_pokemon_data(episode, names, season)\n",
    "        plot = get_episode_plot(episode, season)\n",
    "        episode_dict[episode] = []\n",
    "        episode_dict[episode].append(episode_pokemon)\n",
    "        episode_dict[episode].append(plot)\n",
    "    return episode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we can get the pokemon data for each episode\n",
    "# first, we get the names of all pokemon from the initial dataframe\n",
    "names = poke_df_clean['pokemon'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then, we start collecting data for each season\n",
    "# this requires a bit of manual work, since the episodes are not numbered in a consistent way\n",
    "# also, we need a season dict\n",
    "season_dict = {\n",
    "    'Indigo League': 'EP',\n",
    "    'Adventures on the Orange Islands': 'EP',\n",
    "    'The Johto Journeys': 'EP',\n",
    "    'Hoenn': 'AG',\n",
    "    'Battle Frontier': 'AG',\n",
    "    'Diamond and Pearl': 'DP',\n",
    "    'Black and White': 'BW',\n",
    "    'XY': 'XY',\n",
    "    'Sun and Moon': 'SM',\n",
    "    'Pocket Monsters': 'JN'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('indigo_df.pkl'):\n",
    "    print('Scraping data...')\n",
    "    episode_numbers_indigo_league = [make_number(i) for i in range(1, 81)]\n",
    "    indigo_dict = gather_pokemon_data(episode_numbers_indigo_league, names, 'Indigo League')\n",
    "    indigo_df = pd.DataFrame.from_dict(indigo_dict, orient='index', columns=['pokemon', 'plot'])\n",
    "    indigo_df.to_pickle('indigo_df.pkl')\n",
    "else:\n",
    "    indigo_df = pd.read_pickle('indigo_df.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('orange_df.pkl'):\n",
    "    print('Scraping data...')\n",
    "    episode_numbers_orange_islands = [make_number(i) for i in range(81, 117)]\n",
    "    orange_dict = gather_pokemon_data(episode_numbers_orange_islands, names, 'Adventures on the Orange Islands')\n",
    "    orange_df = pd.DataFrame.from_dict(orange_dict, orient='index', columns=['pokemon', 'plot'])\n",
    "    orange_df.to_pickle('orange_df.pkl')\n",
    "else:\n",
    "    orange_df = pd.read_pickle('orange_df.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('johto_df.pkl'):\n",
    "    print('Scraping data...')\n",
    "    episode_numbers_johto_journeys = [make_number(i) for i in range(117, 275)]\n",
    "    johto_dict = gather_pokemon_data(episode_numbers_johto_journeys, names, 'The Johto Journeys')\n",
    "    johto_df = pd.DataFrame.from_dict(johto_dict, orient='index', columns=['pokemon', 'plot'])\n",
    "    johto_df.to_pickle('johto_df.pkl')\n",
    "else:\n",
    "    johto_df = pd.read_pickle('johto_df.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('hoenn_df.pkl'):\n",
    "    print('Scraping data...')\n",
    "    episode_numbers_hoenn_league = [make_number(i) for i in range(1, 135)]\n",
    "    hoenn_dict = gather_pokemon_data(episode_numbers_hoenn_league, names, 'Hoenn')\n",
    "    hoenn_df = pd.DataFrame.from_dict(hoenn_dict, orient='index', columns=['pokemon', 'plot'])\n",
    "    hoenn_df.to_pickle('hoenn_df.pkl')\n",
    "else:\n",
    "    hoenn_df = pd.read_pickle('hoenn_df.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('battle_df.pkl'):\n",
    "    print('Scraping data...')\n",
    "    episode_numbers_battle_frontier = [make_number(i) for i in range(135, 193)]\n",
    "    battle_dict = gather_pokemon_data(episode_numbers_battle_frontier, names, 'Battle Frontier')\n",
    "    battle_df = pd.DataFrame.from_dict(battle_dict, orient='index', columns=['pokemon', 'plot'])\n",
    "    battle_df.to_pickle('battle_df.pkl')\n",
    "else:\n",
    "    battle_df = pd.read_pickle('battle_df.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('diamond_df.pkl'):\n",
    "    print('Scraping data...')\n",
    "    episode_numbers_diamond_pearl = [make_number(i) for i in range(1, 192)]\n",
    "    diamond_dict = gather_pokemon_data(episode_numbers_diamond_pearl, names, 'Diamond and Pearl')\n",
    "    diamond_df = pd.DataFrame.from_dict(diamond_dict, orient='index', columns=['pokemon', 'plot'])\n",
    "    diamond_df.to_pickle('diamond_df.pkl')\n",
    "else:\n",
    "    diamond_df = pd.read_pickle('diamond_df.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('black_df.pkl'):\n",
    "    print('Scraping data...')\n",
    "    episode_numbers_black_white = [make_number(i) for i in range(1, 143)]\n",
    "    black_dict = gather_pokemon_data(episode_numbers_black_white, names, 'Black and White')\n",
    "    black_df = pd.DataFrame.from_dict(black_dict, orient='index', columns=['pokemon', 'plot'])\n",
    "    black_df.to_pickle('black_df.pkl')\n",
    "else:\n",
    "    black_df = pd.read_pickle('black_df.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('xy_df.pkl'):\n",
    "    print('Scraping data...')\n",
    "    episode_numbers_xy = [make_number(i) for i in range(1, 141)]\n",
    "    xy_dict = gather_pokemon_data(episode_numbers_xy, names, 'XY')\n",
    "    xy_df = pd.DataFrame.from_dict(xy_dict, orient='index', columns=['pokemon', 'plot'])\n",
    "    xy_df.to_pickle('xy_df.pkl')\n",
    "else:\n",
    "    xy_df = pd.read_pickle('xy_df.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('sun_df.pkl'):\n",
    "    print('Scraping data...')\n",
    "    episode_numbers_sun_moon = [make_number(i) for i in range(1, 147)]\n",
    "    sun_dict = gather_pokemon_data(episode_numbers_sun_moon, names, 'Sun and Moon')\n",
    "    sun_df = pd.DataFrame.from_dict(sun_dict, orient='index', columns=['pokemon', 'plot'])\n",
    "    sun_df.to_pickle('sun_df.pkl')\n",
    "else:\n",
    "    sun_df = pd.read_pickle('sun_df.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('pocket_monsters.pkl'):\n",
    "    print('Scraping data...')\n",
    "    episode_numbers_pocket_monsters = [make_number(i) for i in range(1, 148)]\n",
    "    pocket_dict = gather_pokemon_data(episode_numbers_pocket_monsters, names, 'Pocket Monsters')\n",
    "    pocket_df = pd.DataFrame.from_dict(pocket_dict, orient='index', columns=['pokemon', 'plot'])\n",
    "    pocket_df.to_pickle('pocket_monsters.pkl')\n",
    "else:\n",
    "    pocket_df = pd.read_pickle('pocket_monsters.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was quite a bit of work!\n",
    "\n",
    "The only thing left to do is to add a single column to each dataframe that has the season number for that dataframe, and collect the dataframes into that that then has all info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "# collect all the dataframes into one\n",
    "frames = [indigo_df, orange_df, johto_df, hoenn_df, battle_df, diamond_df, black_df, xy_df, sun_df, pocket_df]\n",
    "\n",
    "# add a column for the season\n",
    "for i in range(len(frames)):\n",
    "    frames[i]['season'] = i + 1\n",
    "\n",
    "# combine all the dataframes\n",
    "all_seasons_df = pd.concat(frames)\n",
    "\n",
    "# save the dataframe\n",
    "if not os.path.exists('all_seasons_df.pkl'):\n",
    "    all_seasons_df.to_pickle('all_seasons_df.pkl')\n",
    "else:\n",
    "    all_seasons_df = pd.read_pickle('all_seasons_df.pkl')\n",
    "    print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">pokemon</th>\n",
       "      <th colspan=\"4\" halign=\"left\">plot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>[Pikachu, Mankey, Spearow, Gyarados, Hypnosis,...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>Pokémon - I Choose You! (Japanese: ポケモン！きみにきめた...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>[Poliwag, Pikachu, Mankey, Spearow, Staryu, Pi...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>After battling in the Pokémon League Tournamen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>[Pikachu, Chansey, Lickitung, Meowth, Fearow, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>Ash begins his journey in Johto, a largely une...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>[Entei, Pikachu, Mudkip, Poochyena, Beautifly,...</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>Team Rocket's failed attempt to catch Pikachu ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>[Pikachu, Rhyhorn, Manectric, Pinsir, Meowth, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>The Battle Factory is Ash's next destination—i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>[Bidoof, Pikachu, Starly, Chatot, Mantyke, Meo...</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>It's always exciting when new Pokémon Trainers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>[Minccino, Pikachu, Reshiram, Deerling, Meowth...</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>Ash excitedly arrives in the Unova region alon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>[Pikachu, Furret, Staryu, Pidgeotto, Lickitung...</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>After a quick introduction to Serena, a buddin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>[Pikachu, Mankey, Litten, Staryu, Whimsicott, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>It’s a beautiful day on Melemele Island in the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>[Poliwag, Pikachu, Mankey, Spearow, Dugtrio, E...</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>In Pallet Town, a young Ash Ketchum is beside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pokemon                                                                 \\\n",
       "         count unique                                                top freq   \n",
       "season                                                                          \n",
       "1           80     80  [Pikachu, Mankey, Spearow, Gyarados, Hypnosis,...    1   \n",
       "2           35     35  [Poliwag, Pikachu, Mankey, Spearow, Staryu, Pi...    1   \n",
       "3          158    158  [Pikachu, Chansey, Lickitung, Meowth, Fearow, ...    1   \n",
       "4          134    134  [Entei, Pikachu, Mudkip, Poochyena, Beautifly,...    1   \n",
       "5           58     58  [Pikachu, Rhyhorn, Manectric, Pinsir, Meowth, ...    1   \n",
       "6          191    191  [Bidoof, Pikachu, Starly, Chatot, Mantyke, Meo...    1   \n",
       "7          142    142  [Minccino, Pikachu, Reshiram, Deerling, Meowth...    1   \n",
       "8          140    140  [Pikachu, Furret, Staryu, Pidgeotto, Lickitung...    1   \n",
       "9          146    146  [Pikachu, Mankey, Litten, Staryu, Whimsicott, ...    1   \n",
       "10         147    147  [Poliwag, Pikachu, Mankey, Spearow, Dugtrio, E...    1   \n",
       "\n",
       "        plot                                                                 \n",
       "       count unique                                                top freq  \n",
       "season                                                                       \n",
       "1         80     80  Pokémon - I Choose You! (Japanese: ポケモン！きみにきめた...    1  \n",
       "2         35     35  After battling in the Pokémon League Tournamen...    1  \n",
       "3        158    158  Ash begins his journey in Johto, a largely une...    1  \n",
       "4        134    134  Team Rocket's failed attempt to catch Pikachu ...    1  \n",
       "5         58     58  The Battle Factory is Ash's next destination—i...    1  \n",
       "6        191    191  It's always exciting when new Pokémon Trainers...    1  \n",
       "7        142    142  Ash excitedly arrives in the Unova region alon...    1  \n",
       "8        140    140  After a quick introduction to Serena, a buddin...    1  \n",
       "9        146    146  It’s a beautiful day on Melemele Island in the...    1  \n",
       "10       147    147  In Pallet Town, a young Ash Ketchum is beside ...    1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize the data in each season\n",
    "seasons = all_seasons_df.groupby('season')\n",
    "seasons.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, these dataframes require no cleaning at all! Their purpose is simply to become the backbone of the graph creation, which is the next step in the process. What is important to notice, is that there are big differences between the seasons when it comes to the number of episodes in each. This might play role for the graphs.\n",
    "\n",
    "The next step is to create and analyse all the graphs. This is essentially done in one big function that has been composed by many smaller steps. First, we define the smaller utility functions, and second, the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name_dict = {\"indigo\": \"Indigo League\",\n",
    "                  \"orange\": \"Orange Islands\",\n",
    "                    \"johto\": \"Johto League\",\n",
    "                    \"hoenn\": \"Hoenn League\",\n",
    "                    \"battle\": \"Battle Frontier\",\n",
    "                    \"sinnoh\": \"Sinnoh League\",\n",
    "                    \"unova\": \"Unova League\",\n",
    "                    \"kalos\": \"Kalos League\",\n",
    "                    \"alola\": \"Alola League\",\n",
    "                    \"journeys\": \"Pokémon Journeys\",\n",
    "                    \"all_seasons\": \"All Seasons\"}\n",
    "\n",
    "def make_anime_edgelist(df):\n",
    "    # make a dictionary to store the edges\n",
    "    edgelist = defaultdict(lambda: 0)\n",
    "    # loop over all episodes\n",
    "    for i in tqdm(range(len(df))):\n",
    "        # loop over all pokemon in the episode\n",
    "        for j in range(len(df['pokemon'].iloc[i])):\n",
    "            for k in range(j+1, len(df['pokemon'].iloc[i])):\n",
    "                edgelist[(df['pokemon'].iloc[i][j], df['pokemon'].iloc[i][k])] += 1\n",
    "                edgelist[(df['pokemon'].iloc[i][k], df['pokemon'].iloc[i][j])] += 1\n",
    "\n",
    "    # make the edgelist undirected \n",
    "    edgelist = [(k[0], k[1], v) for k, v in edgelist.items()]\n",
    "\n",
    "    # only keep every other edge to avoid duplicates\n",
    "    edgelist = edgelist[::2]\n",
    "    return edgelist\n",
    "\n",
    "def calc_frac(graph, fields):\n",
    "    \"\"\" Calculate the fraction of neighbors with the same attribute value as the node itself.\"\"\"\n",
    "    fracs = []\n",
    "    for node in graph.nodes:\n",
    "        c = 0\n",
    "        for neighbor in graph.neighbors(node):\n",
    "            if fields[neighbor] == fields[node]:\n",
    "                c += 1\n",
    "        fracs.append(c/graph.degree(node))\n",
    "\n",
    "    return np.mean(fracs)\n",
    "\n",
    "def set_group(graph, group_dict):\n",
    "    nx.set_node_attributes(graph, group_dict, 'group')\n",
    "\n",
    "def frac_same_field(graph, field):\n",
    "    fields = nx.get_node_attributes(graph, field)\n",
    "    return calc_frac(graph, fields)\n",
    "\n",
    "def frac_rand_graph(graph, field):\n",
    "    fields = nx.get_node_attributes(graph, field)\n",
    "    field_list = list(fields.values())\n",
    "    for key in fields.keys():\n",
    "        fields[key] = random.choice(field_list)\n",
    "\n",
    "    return calc_frac(graph, fields)\n",
    "\n",
    "# we use the same seed as before to ensure reproducibility\n",
    "def modularity_test(graph, nswap):\n",
    "    temp_graph = nx.double_edge_swap(graph, nswap=nswap, max_tries=1000000)\n",
    "    partition = community_louvain.best_partition(temp_graph)\n",
    "    return community_louvain.modularity(partition, temp_graph)\n",
    "\n",
    "# time to make a function for all graph analysis\n",
    "def graph_analysis(df, save_name: str, save: bool = False):\n",
    "    # setup relevant folders for saving\n",
    "    if save:\n",
    "        os.makedirs(f'figures/{save_name}', exist_ok=True)\n",
    "\n",
    "    txt_lines = []\n",
    "\n",
    "    # make big print statement\n",
    "    print(f\"Analysing the graph for the {save_name_dict[save_name]} season\")\n",
    "    txt_lines.append(\"Analysing the graph for the \" + save_name_dict[save_name] + \" season\")\n",
    "    # make the initial graph\n",
    "    G = nx.Graph()\n",
    "    print(\"Making graph...\")\n",
    "    G.add_weighted_edges_from(make_anime_edgelist(df))\n",
    "    print(\"Done!\")\n",
    "    txt_lines.append(f\"The graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "\n",
    "    # make dataframe with only pokemon in original df\n",
    "    anime_pokemon = find_unique(df, 'pokemon')\n",
    "    anime_pokemon_df = poke_df_clean[poke_df_clean['pokemon'].isin(anime_pokemon)].reset_index(drop=True)\n",
    "\n",
    "    # remove all nodes that are not in the anime pokemon dataframe\n",
    "    pokemon = anime_pokemon_df['pokemon'].values.tolist()\n",
    "    G.remove_nodes_from([n for n in G.nodes() if n not in pokemon])\n",
    "\n",
    "    # add pokemon attributes to graph\n",
    "    types = [t for t in anime_pokemon_df['types'].values]\n",
    "    type_dict = dict(zip(anime_pokemon_df['pokemon'], types))\n",
    "\n",
    "    abilities = [a for a in anime_pokemon_df['abilities'].values]\n",
    "    ability_dict = dict(zip(anime_pokemon_df['pokemon'], abilities))\n",
    "\n",
    "    egg_groups = [e for e in anime_pokemon_df['egg_groups'].values]\n",
    "    egg_group_dict = dict(zip(anime_pokemon_df['pokemon'], egg_groups))\n",
    "\n",
    "    nx.set_node_attributes(G, type_dict, 'types')\n",
    "    nx.set_node_attributes(G, ability_dict, 'abilities')\n",
    "    nx.set_node_attributes(G, egg_group_dict, 'egg_groups')\n",
    "\n",
    "    # degree rank plot\n",
    "    degree_sequence = sorted([d for _, d in G.degree()], reverse=True)\n",
    "\n",
    "    # plot degree distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(degree_sequence, 'b-', marker='o')\n",
    "    # add the name to the highest degree\n",
    "    plt.title(f\"Degree rank plot for {save_name_dict[save_name]}\")\n",
    "    plt.ylabel(\"degree\")\n",
    "    plt.xlabel(\"rank\")\n",
    "    figure_path = os.path.join('figures', save_name, 'degree_rank_plot.png')\n",
    "    if save:\n",
    "        plt.savefig(figure_path)\n",
    "    plt.close()\n",
    "\n",
    "    # make histogram of degree distribution w. mean\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(degree_sequence, bins=20)\n",
    "    plt.axvline(np.mean(degree_sequence), color='r', linestyle='dashed', linewidth=1)\n",
    "    plt.text(np.mean(degree_sequence) + 10, 100, 'Mean: {:.0f}'.format(np.mean(degree_sequence)))\n",
    "    plt.title(f\"Degree Distribution for {save_name_dict[save_name]}\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"Degree\")\n",
    "    if save:\n",
    "        plt.savefig(os.path.join('figures', save_name, 'degree_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # identify the ten pokemon with the highest degree\n",
    "    sorted_degree = sorted(G.degree, key=lambda x: x[1], reverse=True)\n",
    "    # print the top ten pokemon with the highest degree and their degree value each on one line\n",
    "    txt_lines.append(\"The top ten pokemon with the highest degree are:\")\n",
    "    for i in range(10):\n",
    "        txt_lines.append(f\"{sorted_degree[i][0]}: {sorted_degree[i][1]}\")\n",
    "\n",
    "    # get degree assortativity\n",
    "    dac = nx.degree_assortativity_coefficient(G)\n",
    "    txt_lines.append(f\"The degree assortativity coefficient is {dac:.2f}\")\n",
    "\n",
    "    # explore connections between pokemon types, abilities and egg groups\n",
    "    avg_typing = frac_same_field(G, 'types')\n",
    "    txt_lines.append(f\"The average fraction of neighbors with the same typing as the node itself is {avg_typing*100:.2f}%\")\n",
    "\n",
    "    avg_abilities = frac_same_field(G, 'abilities')\n",
    "    txt_lines.append(f\"The average fraction of neighbors with the same ability as the node itself is {avg_abilities*100:.2f}%\")\n",
    "\n",
    "    avg_egg_groups = frac_same_field(G, 'egg_groups')\n",
    "    txt_lines.append(f\"The average fraction of neighbors with the same egg group as the node itself is {avg_egg_groups*100:.2f}%\")\n",
    "\n",
    "    # now, we repeat the above 100 times and calculate the average fraction of neighbors with the same field as the node itself\n",
    "    avg_rand_type_100 = [frac_rand_graph(G, 'types') for _ in range(100)]\n",
    "    avg_rand_type_100_mu = np.mean(avg_rand_type_100)\n",
    "    txt_lines.append(f\"The average fraction of neighbors with the same typing as the node itself when random is {avg_rand_type_100_mu*100:.2f}%\")\n",
    "    \n",
    "\n",
    "    avg_rand_abilities_100 = [frac_rand_graph(G, 'abilities') for _ in range(100)]\n",
    "    avg_rand_abilities_100_mu = np.mean(avg_rand_abilities_100)\n",
    "    txt_lines.append(f\"The average fraction of neighbors with the same ability as the node itself when random is {avg_rand_abilities_100_mu*100:.2f}%\")\n",
    "\n",
    "    avg_rand_egg_groups_100 = [frac_rand_graph(G, 'egg_groups') for _ in range(100)]\n",
    "    avg_rand_egg_groups_100_mu = np.mean(avg_rand_egg_groups_100)\n",
    "    txt_lines.append(f\"The average fraction of neighbors with the same egg group as the node itself when random is {avg_rand_egg_groups_100_mu*100:.2f}%\")\n",
    "\n",
    "    # now we make three subplots of the random distributions with the actual values plotted as vertical lines with text\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 6), sharey=True)\n",
    "    ax[0].hist(avg_rand_type_100, bins=20)\n",
    "    ax[0].axvline(avg_typing, color='r', linestyle='dashed', linewidth=1)\n",
    "    ax[0].set_title(\"Typing\")\n",
    "    ax[0].set_ylabel(\"Count\")\n",
    "    ax[0].set_xlabel(\"Fraction of neighbors with same typing\")\n",
    "    ax[1].hist(avg_rand_abilities_100, bins=20)\n",
    "    ax[1].axvline(avg_abilities, color='r', linestyle='dashed', linewidth=1)\n",
    "    ax[1].set_title(\"Abilities\")\n",
    "    ax[1].set_xlabel(\"Fraction of neighbors with same ability\")\n",
    "    ax[2].hist(avg_rand_egg_groups_100, bins=20)\n",
    "    ax[2].axvline(avg_egg_groups, color='r', linestyle='dashed', linewidth=1)\n",
    "    ax[2].set_title(\"Egg Groups\")\n",
    "    ax[2].set_xlabel(\"Fraction of neighbors with same egg group\")\n",
    "    \n",
    "    plt.suptitle(f\"Random distributions for {save_name_dict[save_name]}\")\n",
    "    if save:\n",
    "        plt.savefig(os.path.join('figures', save_name, 'random_distributions.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # make statistical tests for the three fields\n",
    "    import scipy.stats as stats\n",
    "    txt_lines.append(\"Statistical tests for the three fields:\")\n",
    "\n",
    "    p_val_typing = stats.ttest_1samp(avg_rand_type_100, avg_typing)[1]\n",
    "    txt_lines.append(f\"Typing: {p_val_typing}\")\n",
    "\n",
    "    p_val_abilities = stats.ttest_1samp(avg_rand_abilities_100, avg_abilities)[1]\n",
    "    txt_lines.append(f\"Abilities: {p_val_abilities}\")\n",
    "\n",
    "    p_val_egg_groups = stats.ttest_1samp(avg_rand_egg_groups_100, avg_egg_groups)[1]\n",
    "    txt_lines.append(f\"Egg Groups: {p_val_egg_groups}\")\n",
    "    \n",
    "\n",
    "    # find best partition\n",
    "    partition = community_louvain.best_partition(G)\n",
    "    # print the modularity\n",
    "    mod = community_louvain.modularity(partition, G)\n",
    "    txt_lines.append(f\"The modularity is {mod:.2f}\")\n",
    "\n",
    "    num_communities = len(set(partition.values()))\n",
    "    txt_lines.append(f\"There are {num_communities} communities\")\n",
    "\n",
    "    # Community sizes\n",
    "    community_sizes = [len(list(filter(lambda x: x[1] == i, partition.items()))) for i in range(num_communities)]\n",
    "    txt_lines.append(f\"The community sizes are {community_sizes}\")\n",
    "\n",
    "    # add the community as an attribute to the nodes\n",
    "    set_group(G, partition)\n",
    "\n",
    "    # time to test modularity\n",
    "    txt_lines.append(\"Testing modularity\")\n",
    "    print(\"Testing modularity\")\n",
    "    if save_name != 'all_seasons':\n",
    "        # if we are using the all seasons graph, we need to remove the edges between seasons\n",
    "        \n",
    "        mods = []\n",
    "        for _ in tqdm(range(100)):\n",
    "            mods.append(modularity_test(G, G.number_of_edges()/2))\n",
    "        txt_lines.append(f\"The average modularity after double edge swap test is {np.mean(mods):.2f}\")\n",
    "        # statistical test\n",
    "        p_val_mod = stats.ttest_1samp(mods, mod)[1]\n",
    "        txt_lines.append(f\"The p-value for the modularity test is {p_val_mod}\")\n",
    "\n",
    "        # plot the distribution of modularity values with the actual modularity value plotted as a vertical line\n",
    "        plt.hist(mods, bins=20)\n",
    "        plt.axvline(mod, color='r', linestyle='dashed', linewidth=1)\n",
    "        plt.title(f\"Modularity distribution for {save_name_dict[save_name]}\")\n",
    "        plt.xlabel(\"Modularity\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        if save:\n",
    "            plt.savefig(os.path.join('figures', save_name, 'modularity_distribution.png'))\n",
    "        plt.close()\n",
    "\n",
    "    # write all the text lines to a file\n",
    "    with open(os.path.join('txt_files', f'{save_name}_text.txt'), 'w') as f:\n",
    "        f.write('\\n'.join(txt_lines))\n",
    "\n",
    "    return G\n",
    "\n",
    "def save_graph(G, save_name):\n",
    "    \"\"\"\n",
    "    Saves the graph as a pkl file\n",
    "    \"\"\"\n",
    "    # make the directory if it doesn't exist\n",
    "    \n",
    "    print(f\"Saving graph as {save_name}_G.pkl\")\n",
    "    with open(os.path.join('graphs', f'{save_name}_G.pkl'), 'wb') as f:\n",
    "        pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing the graph for the Indigo League season\n",
      "Making graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 127.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Testing modularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:44<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as indigo_G.pkl\n",
      "Analysing the graph for the Orange Islands season\n",
      "Making graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 129.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Testing modularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as orange_G.pkl\n",
      "Analysing the graph for the Johto League season\n",
      "Making graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:01<00:00, 153.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Testing modularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:16<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as johto_G.pkl\n",
      "Analysing the graph for the Hoenn League season\n",
      "Making graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:01<00:00, 128.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Testing modularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:29<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as hoenn_G.pkl\n",
      "Analysing the graph for the Sinnoh League season\n",
      "Making graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:01<00:00, 102.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Testing modularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:06<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as sinnoh_G.pkl\n",
      "Analysing the graph for the Unova League season\n",
      "Making graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:01<00:00, 140.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Testing modularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:16<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as unova_G.pkl\n",
      "Analysing the graph for the Kalos League season\n",
      "Making graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:01<00:00, 80.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Testing modularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:26<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as kalos_G.pkl\n",
      "Analysing the graph for the Alola League season\n",
      "Making graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [00:02<00:00, 51.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Testing modularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:45<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as alola_G.pkl\n",
      "Analysing the graph for the Pokémon Journeys season\n",
      "Making graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:03<00:00, 37.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Testing modularity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:17<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as journeys_G.pkl\n",
      "Analysing the graph for the All Seasons season\n",
      "Making graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1231/1231 [00:16<00:00, 72.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Testing modularity\n",
      "Saving graph as all_seasons_G.pkl\n"
     ]
    }
   ],
   "source": [
    "# make the graphs\n",
    "name_to_df_dict = {\"indigo\": indigo_df,\n",
    "                   \"orange\": orange_df,\n",
    "                   \"johto\": johto_df,\n",
    "                   \"hoenn\": hoenn_df,\n",
    "                   \"sinnoh\": diamond_df,\n",
    "                   \"unova\": black_df,\n",
    "                   \"kalos\": xy_df,\n",
    "                   \"alola\": sun_df,\n",
    "                   \"journeys\": pocket_df,\n",
    "                   \"all_seasons\": all_seasons_df\n",
    "}\n",
    "\n",
    "# loop through all the dataframes and make the graphs\n",
    "for name, df in name_to_df_dict.items():\n",
    "    if not os.path.exists(os.path.join('graphs', f'{name}_G.pkl')):\n",
    "        G = graph_analysis(df, name, save=True)\n",
    "        save_graph(G, name)\n",
    "    else:\n",
    "        print(f\"Graph for {name} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
